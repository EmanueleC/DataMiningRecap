\section{Model selection}

Un buon modello non deve essere troppo semplice (bias elevato) e nemmeno
troppo complesso (rischio di overfitting), sta nel ``mezzo''.

Il modello perfetto non esiste.

Non esistono regole per inserire i termini nel modello (polinomiali?
termini di interazione?)

I grafici possono essere usati come guida per intuire o ipotizzare relazioni
tra i covarianti. Quali di queste relazioni hanno senso per il problema in esame?

Quali strumenti abbiamo visto per scegliere un modello?

\begin{itemize}
 \item RSS o $R^2$ ma affidarsi solo a loro incrementa il rischio di overfitting.
 \item Analisi dei residui.
 \item F test.
 \item Test di validazione (training vs test), cross validation
 \item Training error e test error
\end{itemize}

Altri criteri visti:

\begin{itemize}
 \item adjusted $R^2$
 \item AIC
 \item BIC
\end{itemize}

\subsection{Akaike information criterion - AIC}

$AIC = 2p - 2log(\hat{\theta})$

dove p = penalizzazione e $\hat{\theta}$ = maximum likelihood estimate.

Per il modello di regressione lineare: $AIC = nlog(RSS) + 2p$.

Per il modello di regressione logistica: $AIC = Devianza + 2p$.

\subsection{Bayesian information criterion - BIC}

$BIC = plog(n) - 2log(\theta)$

dove p = penalizzazione e $\theta$ = likelihood.

Per il modello di regressione lineare: $BIC = nlog(RSS) + plog(n)$.

Per il modello di regressione logistica: $BIC = Devianza + plog(n)$.\\

Più piccoli sono AIC e BIC, più basso è il test error del modello.

La comparazione tra modelli basata su AIC e BIC non richiede che siano
innestati, al contrario di F.

Dipendono dall'unità di misura di Y.






